
version: 2.1
orbs:
  # For slack alerts
  slack: circleci/slack@4.1
  aws-eks: circleci/aws-eks@1.1.0
  kubernetes: circleci/kubernetes@0.12.0

commands:
  
  destroy-environment:
    description: Destroy back-end and front-end cloudformation stacks given a workflow ID.
    parameters:
      workflow_id:
        type: string
    steps:
      - run:
          name: Destroy environments
          no_output_timeout: 30m
          when: on_fail
          command: |
            aws cloudformation delete-stack --stack-name capstone-${CIRCLE_WORKFLOW_ID}
            echo capstone-${CIRCLE_WORKFLOW_ID}
            #exit 1
  
  destroy-deployment:
    description: Destroy k8-environment
    steps:
      - run:
          when: on_fail
          name: delete deploy
          command: |
            echo "**********INSTALLING KUBECTL*******" 
            curl -o kubectl https://amazon-eks.s3.us-west-2.amazonaws.com/1.20.4/2021-04-12/bin/linux/amd64/kubectl
            chmod +x ./kubectl
            aws eks --region us-west-2 update-kubeconfig --name k8-udacapstone
            ./kubectl delete deploy udacapblue-deployment
            ./kubectl delete svc udacap-load-balancer


  destroy-cluster:
    description: Destroy cluster
    steps:
      - run:
          name: Destroy nodegroups
          command: eksctl delete nodegroup --cluster=k8-udacapstone --name=udacaps-k8-nodes
      - run:
          name: Destroy cluster
          command: eksctl delete cluster --name=k8-udacapstone 
jobs: 
  deploy_k8_cluster:
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run: 
          command: |  
            yum -y install tar gzip      
      - run:
          name: Install dependencies
          command: |
            curl --silent --location "https://github.com/weaveworks/eksctl/releases/latest/download/eksctl_$(uname -s)_amd64.tar.gz" | tar xz -C /tmp
            mv /tmp/eksctl /usr/local/bin
      - run:
          name: create cluster
          command: | 
            eksctl create cluster \
            --name k8-udacapstone \
            --version 1.20 \
            --region us-west-2 \
            --nodegroup-name udacaps-k8-nodes \
            --node-type t2.micro \
            --nodes 3          
  
  deploy_blue_deployment:
    docker:  
      - image: amazon/aws-cli
    steps:
      - checkout   
      - run:
          name: Install dependencies
          command: |
            echo "**********INSTALLING KUBECTL*******" 
            curl -o kubectl https://amazon-eks.s3.us-west-2.amazonaws.com/1.20.4/2021-04-12/bin/linux/amd64/kubectl
            chmod +x ./kubectl
            echo "**********INSTALLING TAR*******"
            yum -y install tar gzip

      - run: 
          name: check cluster status
          command: | 
            aws eks --region us-west-2 update-kubeconfig --name k8-udacapstone
            ./kubectl cluster-info
            ./kubectl get nodes -o wide 
            ./kubectl apply -f .circleci/files/udacapblue-dep.yml
            ./kubectl get pods
            ./kubectl get svc
            export UDACAP_BLUE_URL=$(./kubectl get svc udacapblue-lb -o jsonpath='{.status.loadBalancer.ingress[*].hostname}') 
            echo "[url]" >> ".circleci/files/udacap_blue_url.txt"
            echo $UDACAP_BLUE_URL>> ".circleci/files/udacap_blue_url.txt"
      - run:
          name: check variable      
          command: cat .circleci/files/udacap_blue_url.txt
      - persist_to_workspace:
          root: .circleci/files
          paths:
            - uda_capstone_url.txt
      - run: sleep 90;

  deploy_green_deployment:
    docker:  
      - image: amazon/aws-cli
    steps:
      - checkout   
      - run:
          name: Install dependencies
          command: |
            echo "**********INSTALLING KUBECTL*******" 
            curl -o kubectl https://amazon-eks.s3.us-west-2.amazonaws.com/1.20.4/2021-04-12/bin/linux/amd64/kubectl
            chmod +x ./kubectl
            echo "**********INSTALLING TAR*******"
            yum -y install tar gzip

      - run: 
          name: check cluster status
          command: | 
            aws eks --region us-west-2 update-kubeconfig --name k8-udacapstone
            ./kubectl cluster-info
            ./kubectl get nodes -o wide 
            ./kubectl apply -f .circleci/files/uda-capstone-dep.yml
            ./kubectl get pods
            ./kubectl get svc
            export UDA_CAPSTONE_URL=$(./kubectl get svc udacap-load-balancer -o jsonpath='{.status.loadBalancer.ingress[*].hostname}') 
            echo "[url]" >> ".circleci/files/uda_capstone_url.txt"
            echo $UDA_CAPSTONE_URL >> ".circleci/files/uda_capstone_url.txt"
      - run:
          name: check variable      
          command: cat .circleci/files/uda_capstone_url.txt
      - persist_to_workspace:
          root: .circleci/files
          paths:
            - uda_capstone_url.txt
      - run: sleep 90;

  smoke-test:
      docker:
        - image: amazon/aws-cli
      steps:
        - checkout
        - run:
            name: Install dependencies
            command: |
              yum -y install tar gzip
              yum -y install curl
        - attach_workspace:
            at: /tmp/.circleci/files/
        - run:
            name: Get SERVICE URL
            command: |
              cat /tmp/.circleci/files/udacap_blue_url.txt
              UDACAP_BLUE_URL=$(cat /tmp/.circleci/files/udacap_blue_url.txt| grep -v "url")
              echo "${UDACAP_BLUE_URL}"
              curl -Is http://${UDACAP_BLUE_URL}       
        - destroy-deployment

  deploy_client:
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run:
          name: creates infrastructure
          command: |
            aws cloudformation deploy --template-file .circleci/files/client.yml --tags project=udacity --stack-name capstone-${CIRCLE_WORKFLOW_ID} --parameter-overrides ID=client-${CIRCLE_WORKFLOW_ID} 
      - run: 
          command: |  
            yum -y install tar gzip
      - run:
          name: Add back-end ip to ansible inventory
          command: |
            rm .circleci/ansible/inventory.txt # clears the inventory file to have only the existing instances
            echo "[web]" > .circleci/ansible/inventory.txt
            aws ec2 describe-instances \
              --query 'Reservations[*].Instances[*].PublicIpAddress' \
              --filters "Name=tag:project,Values=udacity" \
              --output text >> .circleci/ansible/inventory.txt
            cat .circleci/ansible/inventory.txt
            ls ~/
      - persist_to_workspace:
          root: .circleci/ansible
          paths:
            - inventory.txt
      - destroy-environment:
          workflow_id: ${CIRCLE_WORKFLOW_ID}

  configure_client:
    docker:
      - image: python:3.7-alpine3.11
    steps:
      - checkout
      - add_ssh_keys:
          fingerprints: ["41:6b:ff:3f:03:16:d6:a6:77:b9:d0:46:81:95:ca:83"]
      - attach_workspace:
          at: /tmp/.circleci/ansible
      - run:
          name: Install dependencies
          command: |
            apk add --no-cache \
                python3 \
                py3-pip \
            && pip3 install --upgrade pip \
            && pip3 install \
                awscli \
            && rm -rf /var/cache/apk/*
            apk add --update ansible     
      - run:
          name: Configure server
          command: |
            cat .circleci/ansible/inventory.txt
            ansible-playbook -i /tmp/.circleci/ansible/inventory.txt .circleci/ansible/deploy-client.yml
      - destroy-environment:
          workflow_id: ${CIRCLE_WORKFLOW_ID}
          
workflows:
  default:
    jobs:
#      - deploy_k8_cluster
      - deploy_blue_deployment
#      - deploy_green_deployment
#          requires: [deploy_k8_cluster]
#      - sleep_60s:
#           requires: [deploy_k8_deployment]
#      - deploy_client:
      - smoke-test:
            requires: [deploy_blue_deployment]
#      - deploy_client:
#         requires: [deploy_k8_deployment]
#      - configure_client:
#           requires: [deploy_client]
      


